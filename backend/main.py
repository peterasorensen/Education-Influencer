"""
FastAPI Backend for Educational Video Generation Pipeline

Provides REST API and WebSocket endpoints for generating educational videos
with multi-voice narration, Manim animations, and audio synthesis.
"""

import logging
import asyncio
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime
import os
import uuid

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, BackgroundTasks
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn
from dotenv import load_dotenv

from pipeline import (
    ScriptGenerator,
    AudioGenerator,
    TimestampExtractor,
    VisualScriptGenerator,
    ManimGenerator,
    ImageToVideoGenerator,
    LipsyncGenerator,
    VideoStitcher,
)

# Load environment variables from .env file
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Educational Video Generation API",
    description="Generate educational videos with AI-powered narration and Manim animations",
    version="1.0.0",
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "https://education-influencer.vercel.app",
        "https://eduvideo.bankrupt.fyi",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Load environment variables
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.warning("OPENAI_API_KEY not set. API calls will fail.")

REPLICATE_API_TOKEN = os.getenv("REPLICATE_API_TOKEN")
if not REPLICATE_API_TOKEN:
    logger.warning("REPLICATE_API_TOKEN not set. Celebrity video generation will fail.")

# Output directories
BASE_OUTPUT_DIR = Path("./output")
BASE_OUTPUT_DIR.mkdir(exist_ok=True)

# Celebrity assets
ASSETS_DIR = Path("./assets")
CELEBRITY_IMAGES = {
    "drake": ASSETS_DIR / "drake.jpg",
    "sydney_sweeney": ASSETS_DIR / "sydneysweeney.png",
}


def cleanup_old_outputs():
    """Clean up old output directories and media folder on startup to save space."""
    import shutil

    # Clean up output directories
    if BASE_OUTPUT_DIR.exists():
        logger.info("Cleaning up old output directories...")
        cleaned = 0
        for old_dir in BASE_OUTPUT_DIR.iterdir():
            if old_dir.is_dir() and old_dir.exists():
                try:
                    shutil.rmtree(old_dir)
                    cleaned += 1
                except Exception as e:
                    logger.warning(f"Failed to clean up {old_dir}: {e}")
        logger.info(f"Cleaned up {cleaned} old output directories")

    # Clean up media directory (Manim autogenerated)
    media_dir = Path("./media")
    if media_dir.exists():
        logger.info("Cleaning up media directory...")
        try:
            shutil.rmtree(media_dir)
            logger.info("Media directory cleaned up")
        except Exception as e:
            logger.warning(f"Failed to clean up media directory: {e}")

# Active WebSocket connections
active_connections: Dict[str, WebSocket] = {}

# Job status tracking
job_status: Dict[str, Dict[str, Any]] = {}


# Request/Response Models
class VideoGenerationRequest(BaseModel):
    """Request model for video generation."""

    topic: str = Field(..., description="Educational topic for the video")
    duration_seconds: int = Field(
        default=60, ge=30, le=300, description="Target video duration in seconds"
    )
    quality: str = Field(
        default="medium_quality",
        description="Video quality (low_quality, medium_quality, high_quality)",
    )
    enable_subtitles: bool = Field(
        default=True, description="Whether to add subtitles to the final video"
    )
    celebrity: str = Field(
        default="drake",
        description="Celebrity for lip-synced video (drake, sydney_sweeney)",
    )


class VideoGenerationResponse(BaseModel):
    """Response model for video generation."""

    job_id: str = Field(..., alias="jobId", description="Unique job identifier")
    status: str = Field(..., description="Job status")
    message: str = Field(..., description="Status message")

    class Config:
        populate_by_name = True
        by_alias = True


class JobStatusResponse(BaseModel):
    """Response model for job status."""

    job_id: str
    status: str
    progress: int
    message: str
    video_url: Optional[str] = None
    error: Optional[str] = None


# Helper Functions
def get_pipeline_step_from_progress(progress: int) -> str:
    """Map progress percentage to pipeline step."""
    if progress < 15:
        return "generating_script"
    elif progress < 35:
        return "creating_audio"
    elif progress <= 45:
        return "extracting_timestamps"
    elif progress < 50:
        return "planning_visuals"
    elif progress < 60:
        return "generating_animations"
    elif progress < 75:
        return "creating_celebrity_videos"
    elif progress < 90:
        return "lip_syncing"
    else:
        return "compositing_video"


def get_step_status(progress: int, step: str) -> str:
    """Determine status of a step based on current progress."""
    current_step = get_pipeline_step_from_progress(progress)
    steps_order = [
        "generating_script",
        "creating_audio",
        "extracting_timestamps",
        "planning_visuals",
        "generating_animations",
        "creating_celebrity_videos",
        "lip_syncing",
        "compositing_video"
    ]

    if steps_order.index(step) < steps_order.index(current_step):
        return "completed"
    elif step == current_step:
        return "in_progress"
    else:
        return "pending"


def calculate_step_progress(overall_progress: int, step: str) -> int:
    """Calculate individual step progress (0-100) based on overall progress."""
    step_ranges = {
        "generating_script": (0, 15),
        "creating_audio": (15, 35),
        "extracting_timestamps": (35, 45),
        "planning_visuals": (45, 50),
        "generating_animations": (50, 60),
        "creating_celebrity_videos": (60, 75),
        "lip_syncing": (75, 90),
        "compositing_video": (90, 100)
    }

    if step not in step_ranges:
        return 0

    start, end = step_ranges[step]

    if overall_progress < start:
        return 0
    elif overall_progress >= end:
        return 100
    else:
        # Calculate progress within this step's range
        step_range = end - start
        progress_in_step = overall_progress - start
        return int((progress_in_step / step_range) * 100)


async def send_progress_update(job_id: str, message: str, progress: int):
    """
    Send progress update via WebSocket.

    Args:
        job_id: Job identifier
        message: Progress message
        progress: Progress percentage (0-100)
    """
    # Update job status
    if job_id in job_status:
        job_status[job_id]["progress"] = progress
        job_status[job_id]["message"] = message
        job_status[job_id]["status"] = "processing"

    # Send WebSocket update if connected
    if job_id in active_connections:
        try:
            steps_order = [
                "generating_script",
                "creating_audio",
                "extracting_timestamps",
                "planning_visuals",
                "generating_animations",
                "creating_celebrity_videos",
                "lip_syncing",
                "compositing_video"
            ]

            # Send progress for ALL steps with their individual progress
            for step in steps_order:
                step_progress = calculate_step_progress(progress, step)
                current_step = get_pipeline_step_from_progress(progress)

                if step_progress == 100:
                    status = "completed"
                elif step == current_step:
                    status = "in_progress"
                else:
                    status = "pending"

                await active_connections[job_id].send_json({
                    "type": "progress",
                    "data": {
                        "step": step,
                        "status": status,
                        "message": message if step == current_step else "",
                        "progress": step_progress
                    }
                })
        except Exception as e:
            logger.error(f"Failed to send WebSocket update: {e}")


async def send_completion(job_id: str, video_url: str, topic: str = "", duration: float = 0):
    """Send completion notification via WebSocket."""
    if job_id in job_status:
        job_status[job_id]["status"] = "completed"
        job_status[job_id]["progress"] = 100
        job_status[job_id]["video_url"] = video_url

    if job_id in active_connections:
        try:
            # Mark all steps as completed
            steps_order = [
                "generating_script",
                "creating_audio",
                "extracting_timestamps",
                "planning_visuals",
                "generating_animations",
                "creating_celebrity_videos",
                "lip_syncing",
                "compositing_video"
            ]

            for step in steps_order:
                await active_connections[job_id].send_json({
                    "type": "progress",
                    "data": {
                        "step": step,
                        "status": "completed",
                        "message": f"{step.replace('_', ' ').title()} complete",
                        "progress": 100
                    }
                })

            # Send final completion message
            await active_connections[job_id].send_json({
                "type": "complete",
                "data": {
                    "videoUrl": video_url,
                    "duration": duration,
                    "topic": topic
                }
            })
        except Exception as e:
            logger.error(f"Failed to send completion: {e}")


async def send_error(job_id: str, error: str):
    """Send error notification via WebSocket."""
    if job_id in job_status:
        job_status[job_id]["status"] = "failed"
        job_status[job_id]["error"] = error

    if job_id in active_connections:
        try:
            await active_connections[job_id].send_json(
                {"type": "error", "message": error}
            )
        except Exception as e:
            logger.error(f"Failed to send error: {e}")


async def generate_video_pipeline(
    job_id: str,
    topic: str,
    duration_seconds: int,
    quality: str,
    enable_subtitles: bool,
    celebrity: str = "drake",
):
    """
    Main video generation pipeline with celebrity lip-sync.

    Args:
        job_id: Unique job identifier
        topic: Educational topic
        duration_seconds: Target duration
        quality: Video quality setting
        enable_subtitles: Whether to add subtitles
        celebrity: Celebrity for lip-synced video (drake, sydney_sweeney)
    """
    try:
        # Wait for WebSocket connection before starting
        logger.info(f"Waiting for WebSocket connection for job {job_id}")
        max_wait_time = 30  # Wait up to 30 seconds for WebSocket connection
        wait_interval = 0.5
        waited = 0

        while job_id not in active_connections and waited < max_wait_time:
            await asyncio.sleep(wait_interval)
            waited += wait_interval

        if job_id not in active_connections:
            logger.warning(f"WebSocket not connected after {max_wait_time}s, proceeding anyway for job {job_id}")
        else:
            logger.info(f"WebSocket connected, starting video generation for job {job_id}: {topic}")

        # Ensure output directory exists
        BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        # Create job output directory
        job_dir = BASE_OUTPUT_DIR / job_id
        job_dir.mkdir(parents=True, exist_ok=True)

        # Initialize pipeline modules
        script_gen = ScriptGenerator(OPENAI_API_KEY)
        audio_gen = AudioGenerator(OPENAI_API_KEY)
        timestamp_ext = TimestampExtractor(OPENAI_API_KEY)
        visual_gen = VisualScriptGenerator(OPENAI_API_KEY)
        manim_gen = ManimGenerator(OPENAI_API_KEY)

        # Image-to-video with configurable model (defaults to seedance for cost savings)
        img_to_video_model = os.getenv("IMAGE_TO_VIDEO_MODEL")
        img_to_video_gen = ImageToVideoGenerator(REPLICATE_API_TOKEN, model=img_to_video_model)

        # Lip-sync with configurable model (defaults to kling for cost savings)
        lipsync_model = os.getenv("LIPSYNC_MODEL")
        lipsync_gen = LipsyncGenerator(REPLICATE_API_TOKEN, model=lipsync_model)

        video_stitcher = VideoStitcher()

        # Get celebrity image
        celebrity_image = CELEBRITY_IMAGES.get(celebrity, CELEBRITY_IMAGES["drake"])
        if not celebrity_image.exists():
            raise FileNotFoundError(f"Celebrity image not found: {celebrity_image}")

        # Step 1: Generate Script
        await send_progress_update(job_id, "Generating script...", 5)
        script = await script_gen.generate_script(
            topic=topic,
            duration_seconds=duration_seconds,
            progress_callback=lambda msg, prog: asyncio.create_task(
                send_progress_update(job_id, msg, prog)
            ),
        )
        logger.info(f"Script generated with {len(script)} segments")

        # Save script
        script_path = job_dir / "script.json"
        import json
        script_path.write_text(json.dumps(script, indent=2), encoding="utf-8")

        # Step 2: Generate Audio
        await send_progress_update(job_id, "Generating audio...", 20)
        audio_dir = job_dir / "audio_segments"
        final_audio_path = job_dir / "narration.mp3"
        await audio_gen.generate_full_audio(
            script=script,
            output_dir=audio_dir,
            final_output_path=final_audio_path,
            progress_callback=lambda msg, prog: asyncio.create_task(
                send_progress_update(job_id, msg, prog)
            ),
        )
        logger.info(f"Audio generated: {final_audio_path}")

        # Step 3: Extract Timestamps
        await send_progress_update(job_id, "Extracting timestamps...", 45)
        srt_path = job_dir / "subtitles.srt"
        timestamp_data = await timestamp_ext.extract_timestamps(
            audio_path=final_audio_path,
            output_srt_path=srt_path,
            progress_callback=lambda msg, prog: asyncio.create_task(
                send_progress_update(job_id, msg, prog)
            ),
        )
        logger.info(f"Timestamps extracted: {len(timestamp_data['segments'])} segments")

        # Align script with timestamps
        aligned_script = await timestamp_ext.align_script_with_timestamps(
            script=script,
            timestamp_data=timestamp_data,
            progress_callback=lambda msg, prog: asyncio.create_task(
                send_progress_update(job_id, msg, prog)
            ),
        )

        # Step 4: Generate Visual Instructions
        await send_progress_update(job_id, "Generating visual instructions...", 55)
        visual_instructions = await visual_gen.generate_visual_instructions(
            script=script,
            topic=topic,
            aligned_timestamps=aligned_script,
            progress_callback=lambda msg, prog: asyncio.create_task(
                send_progress_update(job_id, msg, prog)
            ),
        )
        logger.info(f"Visual instructions generated: {len(visual_instructions)} segments")

        # Save visual instructions
        visual_path = job_dir / "visual_instructions.json"
        visual_path.write_text(
            json.dumps(visual_instructions, indent=2), encoding="utf-8"
        )

        # Step 5: Generate Manim Code
        await send_progress_update(job_id, "Generating Manim code...", 50)
        manim_file = job_dir / "animation.py"
        audio_duration = timestamp_data.get('duration', 60.0)
        await manim_gen.generate_manim_code(
            visual_instructions=visual_instructions,
            topic=topic,
            output_path=manim_file,
            target_duration=audio_duration,
            progress_callback=lambda msg, prog: asyncio.create_task(
                send_progress_update(job_id, msg, prog)
            ),
        )
        logger.info(f"Manim code generated: {manim_file}")

        # Step 6: Render Manim Video (TOP HALF - 9:16 format)
        # Wrap in retry loop in case full render fails with errors test render missed
        manim_video = None
        for render_attempt in range(3):  # Up to 3 render attempts
            try:
                await send_progress_update(job_id, f"Rendering Manim animation (attempt {render_attempt + 1}/3)...", 55)
                manim_output_dir = job_dir / "manim_output"
                manim_video = await manim_gen.render_manim_video(
                    manim_file=manim_file,
                    output_dir=manim_output_dir,
                    quality=quality,
                    aspect_ratio="9:16",  # Mobile-friendly 9:16 aspect ratio
                    progress_callback=lambda msg, prog: asyncio.create_task(
                        send_progress_update(job_id, msg, prog)
                    ),
                )
                logger.info(f"Manim video rendered: {manim_video}")
                break  # Success! Exit retry loop
            except Exception as render_error:
                logger.warning(f"Manim render attempt {render_attempt + 1} failed: {render_error}")
                if render_attempt < 2:  # Not last attempt
                    # Regenerate code with the render error
                    await send_progress_update(job_id, f"Render failed, regenerating code...", 52)
                    manim_file = await manim_gen.generate_manim_code(
                        visual_instructions=visual_instructions,
                        topic=topic,
                        output_path=manim_file,
                        target_duration=audio_duration,
                        progress_callback=lambda msg, prog: asyncio.create_task(
                            send_progress_update(job_id, msg, prog)
                        ),
                    )
                    logger.info(f"Manim code regenerated after render failure")
                else:
                    # Last attempt failed, raise error
                    raise

        if not manim_video:
            raise Exception("Failed to render Manim video after 3 attempts")

        # Step 7: Generate Celebrity Videos from Image (BOTTOM HALF) - PER SEGMENT
        await send_progress_update(job_id, "Generating celebrity videos per segment...", 60)

        # Get individual audio segment files
        audio_segment_files = sorted(list(audio_dir.glob("segment_*.mp3")))
        logger.info(f"Found {len(audio_segment_files)} audio segments to process")

        if not audio_segment_files:
            raise Exception("No audio segments found! Cannot generate celebrity videos.")

        # Prepare directories
        celebrity_video_dir = job_dir / "celebrity_videos"
        celebrity_video_dir.mkdir(parents=True, exist_ok=True)

        # Generate celebrity video for each segment
        celebrity_video_segments = []
        total_segments = len(audio_segment_files)

        for idx, audio_segment_path in enumerate(audio_segment_files):
            segment_progress = int(60 + (idx / total_segments) * 15)
            await send_progress_update(
                job_id,
                f"Generating celebrity video {idx + 1}/{total_segments}...",
                segment_progress
            )

            # Get duration of this audio segment using ffprobe
            segment_duration = await video_stitcher._get_duration(audio_segment_path)
            logger.info(f"Segment {idx}: {segment_duration:.2f}s")

            # Generate celebrity video for this segment
            celebrity_segment_path = celebrity_video_dir / f"segment_{idx:03d}.mp4"

            # Use varied prompts for natural variety
            prompts = [
                "natural talking expression, engaging eye contact, friendly smile, slight head nod",
                "expressive speaking, warm expression, subtle gestures, natural movement",
                "animated talking, enthusiastic expression, gentle head tilt, engaging presence",
                "conversational speaking, genuine smile, soft eye contact, relaxed posture",
                "energetic narration, dynamic expression, natural hand gestures, confident delivery",
            ]
            prompt = prompts[idx % len(prompts)]

            await img_to_video_gen.generate_video_from_image(
                image_path=celebrity_image,
                duration=segment_duration,
                prompt=prompt,
                output_path=celebrity_segment_path,
                aspect_ratio="9:16",
            )
            celebrity_video_segments.append(celebrity_segment_path)
            logger.info(f"Celebrity video segment {idx} generated: {celebrity_segment_path}")

        # Step 8: Lip-sync Each Celebrity Video Segment with Its Audio
        await send_progress_update(job_id, "Lip-syncing video segments with audio...", 75)

        lipsynced_video_dir = job_dir / "lipsynced_videos"
        lipsynced_video_dir.mkdir(parents=True, exist_ok=True)

        lipsynced_segments = []

        for idx, (video_segment, audio_segment) in enumerate(zip(celebrity_video_segments, audio_segment_files)):
            segment_progress = int(75 + (idx / total_segments) * 15)
            await send_progress_update(
                job_id,
                f"Lip-syncing segment {idx + 1}/{total_segments}...",
                segment_progress
            )

            # Lip-sync this segment
            lipsynced_segment_path = lipsynced_video_dir / f"lipsynced_{idx:03d}.mp4"

            await lipsync_gen.sync_audio_to_video(
                video_path=video_segment,
                audio_path=audio_segment,
                output_path=lipsynced_segment_path,
            )
            lipsynced_segments.append(lipsynced_segment_path)
            logger.info(f"Lip-synced segment {idx} created: {lipsynced_segment_path}")

        # Step 8b: Concatenate all lip-synced segments into one video
        await send_progress_update(job_id, "Concatenating lip-synced segments...", 88)

        lipsynced_video = job_dir / "celebrity_lipsynced_full.mp4"

        await video_stitcher.concatenate_videos(
            video_paths=lipsynced_segments,
            output_path=lipsynced_video,
            progress_callback=lambda msg, prog: asyncio.create_task(
                send_progress_update(job_id, msg, int(88 + prog * 0.02))
            ),
        )
        logger.info(f"All lip-synced segments concatenated: {lipsynced_video}")

        # Step 9: Composite Top (Manim) and Bottom (Celebrity) into 9:16 Video
        await send_progress_update(job_id, "Compositing educational and celebrity videos...", 90)
        composite_video = job_dir / "composite_video.mp4"

        await video_stitcher.composite_top_bottom_videos(
            top_video_path=manim_video,
            bottom_video_path=lipsynced_video,
            audio_path=final_audio_path,
            output_path=composite_video,
            progress_callback=lambda msg, prog: asyncio.create_task(
                send_progress_update(job_id, msg, int(90 + prog * 0.05))
            ),
        )
        logger.info(f"Composite video created: {composite_video}")

        # Step 10: Add Subtitles (if enabled)
        if enable_subtitles:
            await send_progress_update(job_id, "Adding subtitles...", 95)
            final_video = job_dir / "final_video.mp4"
            await video_stitcher.add_subtitles(
                video_path=composite_video,
                srt_path=srt_path,
                output_path=final_video,
                progress_callback=lambda msg, prog: asyncio.create_task(
                    send_progress_update(job_id, msg, int(95 + prog * 0.05))
                ),
            )
        else:
            final_video = composite_video

        logger.info(f"Final video ready: {final_video}")

        # Send completion
        video_url = f"/api/videos/{job_id}/{final_video.name}"
        video_duration = timestamp_data.get('duration', 0) if 'timestamp_data' in locals() else 0
        await send_completion(job_id, video_url, topic=topic, duration=video_duration)

        logger.info(f"Video generation complete for job {job_id}")

    except Exception as e:
        logger.error(f"Video generation failed for job {job_id}: {e}", exc_info=True)
        await send_error(job_id, str(e))


# Startup event
@app.on_event("startup")
async def startup_event():
    """Run cleanup on server startup."""
    cleanup_old_outputs()


# API Endpoints
@app.get("/")
async def root():
    """Root endpoint."""
    return {
        "name": "Educational Video Generation API",
        "version": "1.0.0",
        "status": "running",
    }


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}


@app.post("/api/generate", response_model=VideoGenerationResponse)
async def generate_video(
    request: VideoGenerationRequest, background_tasks: BackgroundTasks
):
    """
    Generate an educational video.

    Args:
        request: Video generation parameters

    Returns:
        Job information including job_id for tracking progress
    """
    try:
        # Validate API key
        if not OPENAI_API_KEY:
            raise HTTPException(
                status_code=500, detail="OpenAI API key not configured"
            )

        # Generate unique job ID
        job_id = str(uuid.uuid4())

        # Initialize job status
        job_status[job_id] = {
            "job_id": job_id,
            "status": "waiting_for_connection",
            "progress": 0,
            "message": "Waiting for WebSocket connection...",
            "topic": request.topic,
            "created_at": datetime.now().isoformat(),
        }

        # Start background task
        background_tasks.add_task(
            generate_video_pipeline,
            job_id=job_id,
            topic=request.topic,
            duration_seconds=request.duration_seconds,
            quality=request.quality,
            enable_subtitles=request.enable_subtitles,
            celebrity=request.celebrity,
        )

        logger.info(f"Video generation job created: {job_id}")

        return VideoGenerationResponse(
            job_id=job_id,
            status="waiting_for_connection",
            message="Video generation job created. Connect to WebSocket to start processing.",
        )

    except Exception as e:
        logger.error(f"Failed to create video generation job: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/jobs/{job_id}", response_model=JobStatusResponse)
async def get_job_status(job_id: str):
    """
    Get status of a video generation job.

    Args:
        job_id: Job identifier

    Returns:
        Current job status
    """
    if job_id not in job_status:
        raise HTTPException(status_code=404, detail="Job not found")

    status = job_status[job_id]
    return JobStatusResponse(
        job_id=status["job_id"],
        status=status["status"],
        progress=status.get("progress", 0),
        message=status.get("message", ""),
        video_url=status.get("video_url"),
        error=status.get("error"),
    )


@app.get("/api/videos/{job_id}/{filename}")
async def get_video(job_id: str, filename: str):
    """
    Download generated video.

    Args:
        job_id: Job identifier
        filename: Video filename

    Returns:
        Video file
    """
    video_path = BASE_OUTPUT_DIR / job_id / filename

    if not video_path.exists():
        raise HTTPException(status_code=404, detail="Video not found")

    return FileResponse(
        path=video_path,
        media_type="video/mp4",
        filename=f"{job_id}_{filename}",
    )


@app.websocket("/ws/{job_id}")
async def websocket_endpoint(websocket: WebSocket, job_id: str):
    """
    WebSocket endpoint for real-time progress updates.

    Args:
        websocket: WebSocket connection
        job_id: Job identifier to track
    """
    await websocket.accept()
    active_connections[job_id] = websocket

    try:
        logger.info(f"WebSocket connected for job {job_id}")

        # Send current status if job exists
        if job_id in job_status:
            status = job_status[job_id]
            await websocket.send_json(
                {
                    "type": "status",
                    "status": status["status"],
                    "progress": status.get("progress", 0),
                    "message": status.get("message", ""),
                }
            )

        # Keep connection alive with periodic pings
        last_ping = asyncio.get_event_loop().time()
        while True:
            try:
                # Wait for messages with timeout
                await asyncio.wait_for(websocket.receive_text(), timeout=1.0)
            except asyncio.TimeoutError:
                # Send ping every 30 seconds to keep connection alive through Cloudflare
                current_time = asyncio.get_event_loop().time()
                if current_time - last_ping > 30:
                    try:
                        await websocket.send_json({"type": "ping"})
                        last_ping = current_time
                    except Exception as e:
                        logger.warning(f"Failed to send ping: {e}")
                        break
                continue
            except WebSocketDisconnect:
                break

    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected for job {job_id}")
    except Exception as e:
        logger.error(f"WebSocket error for job {job_id}: {e}")
    finally:
        if job_id in active_connections:
            del active_connections[job_id]


# Run application
if __name__ == "__main__":
    import sys

    port = int(sys.argv[1]) if len(sys.argv) > 1 else 8000

    logger.info(f"Starting Educational Video Generation API on port {port}")

    import os
    is_production = os.getenv("ENVIRONMENT") == "production"

    # Configure reload to ignore all directories where we write files during video generation
    # This prevents WebSocket disconnections when files are created
    if not is_production:
        logger.info("Development mode: Auto-reload DISABLED to prevent WebSocket disconnections during video generation")
        logger.info("Please manually restart the server when you make code changes")
        reload_enabled = False
    else:
        reload_enabled = False

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=reload_enabled,
        log_level="info",
    )
